{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee84a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import enum\n",
    "\n",
    "os.environ[\"CDF_LIB\"] = \"C:\\cdf3.8.0_64bit_VS2015\\lib\"\n",
    "from spacepy import pycdf\n",
    "from pathlib import Path\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c63aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read hdf files. \n",
    "# file name should contain complete path to the file\n",
    "def readH5File(fileName):\n",
    "    df = pd.DataFrame()\n",
    "    try:\n",
    "        df = pd.read_hdf(fileName)\n",
    "        return df\n",
    "    except:\n",
    "        error = 'Can not read file: ' + fileName \n",
    "        log(error)\n",
    "    return df\n",
    "        \n",
    "# Read txt files. \n",
    "# file name should contain complete path to the file       \n",
    "def readTextFile(fileName):\n",
    "    try:\n",
    "        dataFile = open(fileName, 'r')\n",
    "        txtData = dataFile.read()\n",
    "        return txtData\n",
    "    except:\n",
    "        error = 'Can not read file: ' + fileName \n",
    "        log(error)\n",
    "    \n",
    "    \n",
    "# Read cdf (common data format). Refer https://cdf.gsfc.nasa.gov/\n",
    "# Make sure cdf library is installed and CDF_LIB path is defined\n",
    "# Link : https://spdf.gsfc.nasa.gov/pub/software/cdf/dist/cdf38_0/windows/\n",
    "# os.environ[\"CDF_LIB\"] = \"C:\\cdf3.8.0_64bit_VS2015\\lib\"\n",
    "# Make sure pycdf libray is installed\n",
    "def readCDFFile(fileName):\n",
    "    try:\n",
    "        cdfFile = pycdf.CDF(fileName)\n",
    "        return cdfFile\n",
    "    except:\n",
    "        error = 'Can not read file: ' + fileName \n",
    "        log(error)\n",
    "        \n",
    "def saveToHDFFile(dataframe, filePath):\n",
    "    try:\n",
    "        dataframe.to_hdf(filePath, key='df')\n",
    "    except:\n",
    "        error = 'Failed to save dataframe: ' + filePath \n",
    "        log(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefbef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates number of days between given dates\n",
    "# this is used verify there are accurate number of entries in the data set\n",
    "def numberOfDaysInDates(start, end):\n",
    "    startDate = datetime.strptime(start, dateFormat)\n",
    "    endDate = datetime.strptime(end, dateFormat)\n",
    "    delta = endDate - startDate\n",
    "    return delta.days + 1\n",
    "\n",
    "\n",
    "# An empty dataframe is initialised with the given metadata\n",
    "# attribute name in metadata is used to create the column names\n",
    "def initDataFrame(metadata):\n",
    "    columnNames = []\n",
    "    for element in metadata:\n",
    "        attribute = element[_attribute] if _attribute in element else ''\n",
    "        columnNames.append(attribute)   \n",
    "        \n",
    "    df = pd.DataFrame(columns=columnNames)\n",
    "    return df\n",
    "\n",
    "\n",
    "# extract data values from text lines based on the given meta data\n",
    "# metadata comprises what is the data, type of the data and positions need to be extracted\n",
    "# Threshold value: if the attribute value goes beyond thresold value then it is considered as NaN\n",
    "def extractDataFromTxtLine(txt, metadata):\n",
    "    value = {}\n",
    "    for element in metadata:\n",
    "        attribute = element[_attribute] if _attribute in element else ''\n",
    "        startPosition = element[_start_position] if _start_position in element else 0\n",
    "        endPosition = element[_end_position] if _end_position in element else 0\n",
    "        thresholdValue = element[_threshold_value] if _threshold_value in element else 0\n",
    "        dataDateFormat = element[_date_format] if _date_format in element else None\n",
    "        try:\n",
    "            attrValue = txt[startPosition:endPosition]\n",
    "            if attrValue == '':\n",
    "                break\n",
    "            if thresholdValue != 0:\n",
    "                try:\n",
    "                    attrValue = float(attrValue)\n",
    "                    attrValue = float('NaN') if attrValue <= 0 else attrValue\n",
    "                    # checks attribute value goes above threshold value. if goes beyod invalidate\n",
    "                    if attrValue > thresholdValue:\n",
    "                        attrValue = float('NaN')\n",
    "                except:\n",
    "                    attrValue = float('NaN')\n",
    "                    error = 'Value cannot be converted to float'\n",
    "                    log(error)\n",
    "            value[attribute] = attrValue\n",
    "        except:\n",
    "            error = 'No data available at this position'\n",
    "            log(error)\n",
    "    return value\n",
    "\n",
    "\n",
    "# make date formats in data to yyyy-mm-dd\n",
    "# remove redundant datas\n",
    "# add values to time series from start date to end date if any entries are missing\n",
    "def cleanAndFormatData(data, metadata):\n",
    "    dataDateFormat = None\n",
    "    for element in metadata:\n",
    "        dataDateFormat = element[_date_format] if _date_format in element else None\n",
    "    # set date format to yyyy-mm-dd\n",
    "    data[_date] = pd.to_datetime(data[_date], format=dataDateFormat)\n",
    "    \n",
    "    # extract data only inbetween start date and end date(analysis time period)\n",
    "    data = data[(data[_date] >= startDate) & (data[_date] <= endDate)]\n",
    "    \n",
    "    \n",
    "    # set date as index for the dataframe\n",
    "    data = data.set_index(_date)\n",
    "    \n",
    "    # remove duplicates\n",
    "    data = data[~data.index.duplicated(keep='first')]\n",
    "    \n",
    "    #check final data set has accurate number of entries\n",
    "    dataLength = data.shape[0]\n",
    "    if dataLength != numberOfDays:\n",
    "        error = 'Number of entries mismatch. Check data'\n",
    "        log(error)\n",
    "        log('Automatic index correction')\n",
    "        data = fillTimeSeries(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "# fill time series index if any dates are missing\n",
    "# index is filled by a start date and end date. \n",
    "# It will check for any date missing between start and end date.\n",
    "# Creates series from start and end date then reindex the original data set with the date series.\n",
    "# fills NaN for missing values\n",
    "def fillTimeSeries(data):\n",
    "    strSDate = datetime.strptime(startDate, '%Y-%m-%d')\n",
    "    strEDate = datetime.strptime(endDate, '%Y-%m-%d')\n",
    "    timeSeries = pd.DataFrame({ _date: pd.Series([strSDate, strEDate])})\n",
    "    timeSeries.set_index(_date, inplace=True)\n",
    "    data = data.append(timeSeries)\n",
    "    idx = pd.date_range(min(data.index), max(data.index))\n",
    "    data = data[~data.index.duplicated(keep='first')]\n",
    "    data = data.reindex(idx, fill_value=float('NaN'))\n",
    "    return data\n",
    "\n",
    "\n",
    "# Fills missing values by interpolation. \n",
    "def fillNaNValueWithInterpolation(data, column):\n",
    "    data[column] = data[column].interpolate()\n",
    "    data[column].head(4)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# calculate moving average with a window\n",
    "# window size is 27 and minimum period is 17\n",
    "def calculateMovingAvg(data, valueColumn, movingAvgColumn):\n",
    "    data[movingAvgColumn] = data[valueColumn].rolling(window=windowSize, min_periods=windowSize-10).mean()\n",
    "    return data\n",
    "\n",
    "\n",
    "# calculate relative difference of original value and moving average value\n",
    "def calculateRelativeDifference(data, valueColumn, movingAvgColumn, relDiffColumn):\n",
    "    data[relDiffColumn] = ((data[valueColumn] - data[movingAvgColumn])/data[movingAvgColumn])*100\n",
    "    return data\n",
    "\n",
    "def getStartAndEndDateOfYear(year):\n",
    "    first_day_of_year = str(year) + '-01-01'\n",
    "    last_day_of_year = str(year) + '-12-31'\n",
    "    \n",
    "    return (first_day_of_year, last_day_of_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dba6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "startYear = 1997\n",
    "endYear = 2020\n",
    "startDate = str(startYear) + '-01-01'\n",
    "endDate = str(endYear) + '-12-31'\n",
    "analysisPeriod = np.arange(startYear, endYear+1)\n",
    "dateFormat = '%Y-%m-%d'\n",
    "numberOfDays = numberOfDaysInDates(startDate, endDate)\n",
    "\n",
    "f10_7_max_value = 300\n",
    "sws_max_value = 900\n",
    "\n",
    "windowSize = 27\n",
    "minPeriod = 20\n",
    "\n",
    "_attribute = 'attribute'\n",
    "_start_position = 'start_position'\n",
    "_end_position = 'end_position'\n",
    "_date = 'date'\n",
    "_threshold_value = 'threshold_value'\n",
    "_date_format = 'date_format'\n",
    "\n",
    "# ------------------f10.7 variables\n",
    "_f10_7 = 'f10_7'\n",
    "_f10_7_ma_27 = 'f10_7_ma_27'\n",
    "_f10_7_rel_diff = 'f10_7_diff_rel'\n",
    "\n",
    "# ------------------solar wind speed variables\n",
    "_sws = 'sws'\n",
    "_sws_ma_27 = 'sws_ma_27'\n",
    "_sws_rel_diff = 'sws_diff_rel'\n",
    "\n",
    "#-------------------total electron content variables\n",
    "\n",
    "\n",
    "final_plot_location = 'C:/Users/davi_fr/Documents/Thesis Project Final/Final Plot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927b8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "F10_7_FOLDER = \"C:/Users/davi_fr/Documents/Project/data/F10.7cm radiofluxindex/\"\n",
    "\n",
    "# dataPosition variable contain how to extarct data from string based on position and length\n",
    "# format: [[attribure, start_position, end_position, threshold_value, date_format],...]\n",
    "# threshold value: \n",
    "f10_7DataPosition = [{_attribute: _date, _start_position: 0,  _end_position: 10},\n",
    "                {_attribute: _f10_7, \n",
    "                 _start_position: 149, \n",
    "                 _end_position: 156, \n",
    "                 _threshold_value: f10_7_max_value, \n",
    "                 _date_format: None}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f10_7_file_path = 'C:/Users/davi_fr/Documents/Thesis Project Final/data/f10_7/f10_7.h5'\n",
    "sws_file_path = 'C:/Users/davi_fr/Documents/Thesis Project Final/data/sws/sws.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05070b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToLogFile(log):\n",
    "    dt = datetime.now()\n",
    "    log = str(dt) + '\\t' + log + '\\n' \n",
    "    file_name = 'log_file.txt'\n",
    "    f = open(file_name, 'a+')  # open file in append mode\n",
    "    f.write(log)\n",
    "    f.close()\n",
    "\n",
    "def log(message):\n",
    "    writeToLogFile(message)\n",
    "#     print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de2ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5 -60.\n",
      " -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5 -30.\n",
      " -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5   0.\n",
      "   2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5  30.\n",
      "  32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5  60.\n",
      "  62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5]\n"
     ]
    }
   ],
   "source": [
    "testLatitudes = np.arange(-87.5, 90, 2.5)\n",
    "print(testLatitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906a4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tec_rel_diff = \"C:\\\\Users\\\\davi_fr\\\\Documents\\\\Thesis Project Final\\\\tets folder main\\\\test\\\\computations\\\\relative_difference\\\\tec\"\n",
    "tec_file = \"C:\\\\Users\\\\davi_fr\\\\Documents\\\\Thesis Project Final\\\\tets folder main\\\\test\\\\data_formatting\\\\tec_og\"\n",
    "\n",
    "tecRelDiffColumnName = \"tec_rel_diff_lat_\"\n",
    "tecColumnName = \"tec_lat_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef5b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getTECDataAtLatitude(latitude):\n",
    "    tec_data_values = pd.DataFrame()\n",
    "    for year in analysisPeriod:\n",
    "        tec_file_path = tec_rel_diff + \"\\\\\" + str(year) + \".h5\"\n",
    "        tec_og_file_path = tec_file + \"\\\\\" + str(year) + \".h5\"\n",
    "\n",
    "        tecData = readH5File(tec_file_path)\n",
    "        tecOGData = readH5File(tec_og_file_path)\n",
    "\n",
    "        tecData = pd.DataFrame(tecData[[latitude]].mean(axis=1).groupby(level='date').mean())\n",
    "        tecOGData = pd.DataFrame(tecOGData[[latitude]].mean(axis=1).groupby(level='date').mean())\n",
    "\n",
    "\n",
    "        tecData.columns = [tecRelDiffColumnName+str(latitude)]\n",
    "        tecData[tecColumnName+str(latitude)] = tecOGData\n",
    "        tecData.index =  pd.to_datetime(tecData.index, format='%Y-%m-%d')\n",
    "        tec_data_values = tec_data_values.append(tecData)\n",
    "    return tec_data_values\n",
    "\n",
    "# tec_data = getTECDataAtLatitude(0)    \n",
    "# print(tec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70a16a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            f10_7  f10_7_rel_diff\n",
      "date                             \n",
      "1997-01-01   70.0             NaN\n",
      "1997-01-02   69.7             NaN\n",
      "1997-01-03   70.8             NaN\n",
      "1997-01-04   71.4             NaN\n",
      "1997-01-05   71.9             NaN\n",
      "...           ...             ...\n",
      "2020-12-27   84.9        0.258048\n",
      "2020-12-28   84.3        0.290813\n",
      "2020-12-29   81.4       -2.276567\n",
      "2020-12-30   80.1       -2.983133\n",
      "2020-12-31   78.5       -4.298551\n",
      "\n",
      "[8766 rows x 2 columns]\n",
      "               sws  sws_rel_diff\n",
      "1997-01-01     NaN           NaN\n",
      "1997-01-02     NaN           NaN\n",
      "1997-01-03     NaN           NaN\n",
      "1997-01-04     NaN           NaN\n",
      "1997-01-05     NaN           NaN\n",
      "...            ...           ...\n",
      "2020-12-27  463.09     17.168871\n",
      "2020-12-28  486.17     22.138036\n",
      "2020-12-29  467.50     16.778766\n",
      "2020-12-30  478.41     18.260138\n",
      "2020-12-31  398.60     -1.849074\n",
      "\n",
      "[8766 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "f10_7_rel_diff_file = \"C:\\\\Users\\\\davi_fr\\\\Documents\\\\Thesis Project Final\\\\tets folder main\\\\test\\\\computations\\\\relative_difference\\\\f10_7\\\\f10_7.h5\"\n",
    "f10_7_rel_diff = readH5File(f10_7_rel_diff_file)\n",
    "\n",
    "f10_7_file = \"C:\\\\Users\\\\davi_fr\\\\Documents\\\\Thesis Project Final\\\\tets folder main\\\\test\\\\data_formatting\\\\f10_7\\\\f10_7.h5\"\n",
    "f10_7Data = readH5File(f10_7_file)\n",
    "f10_7Data['f10_7_rel_diff'] = f10_7_rel_diff['f10_7']\n",
    "print(f10_7Data)\n",
    "\n",
    "sws_rel_diff_file = \"C:\\\\Users\\\\davi_fr\\\\Documents\\\\Thesis Project Final\\\\tets folder main\\\\test\\\\computations\\\\relative_difference\\\\sws\\\\sws.h5\"\n",
    "sws_rel_diff = readH5File(sws_rel_diff_file)\n",
    "\n",
    "\n",
    "sws_file = \"C:\\\\Users\\\\davi_fr\\\\Documents\\\\Thesis Project Final\\\\tets folder main\\\\test\\\\data_formatting\\\\solar_wind_speed\\\\solar_wind_speed.h5\"\n",
    "swsData = readH5File(sws_file)\n",
    "swsData['sws_rel_diff'] = sws_rel_diff['sws']\n",
    "print(swsData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ecaa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCorrelationWithWindow(latitude, tec_data_file, f10_7Data, swsData):\n",
    "    correlation_window_file = pd.DataFrame(columns=['window_size', 'correlation_tec_f10_7_og', 'correlation_f10_7_rel_diff', 'correlation_sws_rel_diff'])\n",
    "    for windowSize in np.arange(1, 8766):\n",
    "        \n",
    "        correlation_tec_f10_7_og = tec_data_file[tecColumnName+str(latitude)].rolling(windowSize).corr(f10_7Data['f10_7']).mean()\n",
    "        correlation_f10_7_rel_diff = tec_data_file[tecRelDiffColumnName+str(latitude)].rolling(windowSize).corr(f10_7Data['f10_7_rel_diff']).mean()\n",
    "        correlation_sws_rel_diff = tec_data_file[tecRelDiffColumnName+str(latitude)].rolling(windowSize).corr(swsData['sws_rel_diff']).mean()\n",
    "        correlation_sws_og = tec_data_file[tecColumnName+str(latitude)].rolling(windowSize).corr(swsData['sws']).mean()\n",
    "\n",
    "        row = {'window_size': windowSize, \n",
    "               'correlation_tec_f10_7_og': correlation_tec_f10_7_og, \n",
    "               'correlation_f10_7_rel_diff': correlation_f10_7_rel_diff, \n",
    "               'correlation_sws_rel_diff':correlation_sws_rel_diff,\n",
    "               'correlation_sws_og':correlation_sws_og\n",
    "              }\n",
    "        correlation_window_file = correlation_window_file.append(row, ignore_index=True)\n",
    "#     print(correlation_window)  \n",
    "\n",
    "    correlation_window_file.set_index('window_size', inplace = True)\n",
    "    fileName = \"window_size_\" + str(latitude) + \".h5\"\n",
    "    correlation_window_file.to_hdf(\"C:/Users/davi_fr/Documents/Thesis Project Final/source_code/correlation_window_size/\" + fileName, key= 'df')\n",
    "    return correlation_window_file\n",
    "\n",
    "\n",
    "# correlation_window = calculateCorrelationWithWindow(0, tec_data, f10_7Data, swsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec73e16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correlation_window' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19144/3721134571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrelation_window\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'correlation_tec_f10_7_og'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'correlation_f10_7_rel_diff'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'correlation_sws_rel_diff'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# df = df[0:100]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m lgd = ax.legend(['Mean Correlation Coefficient; TEC X F10.7',\n\u001b[0;32m      5\u001b[0m            \u001b[1;34m'Mean Correlation Coefficient; Relative Difference TEC X F10.7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'correlation_window' is not defined"
     ]
    }
   ],
   "source": [
    "df = correlation_window[['correlation_tec_f10_7_og', 'correlation_f10_7_rel_diff', 'correlation_sws_rel_diff']]\n",
    "# df = df[0:100]\n",
    "ax = df.plot(figsize=(12, 5))\n",
    "lgd = ax.legend(['Mean Correlation Coefficient; TEC X F10.7',\n",
    "           'Mean Correlation Coefficient; Relative Difference TEC X F10.7',\n",
    "           'Mean Correlation Coefficient; Relative Difference TEC X Solar Wind Speed',\n",
    "           'Mean Correlation Coefficient; TEC X Solar Wind Speed'], \n",
    "          bbox_to_anchor= (1, -0.2))\n",
    "\n",
    "plt.title('Mean correlation coefficient at 0 degree latitude X Correlation Window Size', pad=20)\n",
    "ax.set_xlabel(\"Window Size\")\n",
    "ax.set_ylabel(\"Correlation Coefficient\")\n",
    "ax.grid('on', which='minor', axis='x' )\n",
    "ax.grid('on', which='major', axis='x' )\n",
    "ax.grid('on', which='minor', axis='y' )\n",
    "ax.grid('on', which='major', axis='y' )\n",
    "\n",
    "minorLocator = MultipleLocator(500)\n",
    "# majorLocator = MultipleLocator(900)\n",
    "ax.xaxis.set_minor_locator(minorLocator)\n",
    "ax.xaxis.set_major_locator(minorLocator)\n",
    "# correlation_window.max()\n",
    "\n",
    "# df.to_excel(\"correlation_window_size.xlsx\") \n",
    "\n",
    "plt.savefig('Mean correlation coefficient at 0 degree latitude X Correlation Window Size.jpg',\n",
    "            bbox_extra_artists=(lgd,), \n",
    "            bbox_inches='tight', dpi= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e96d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________-10.0_______________\n",
      "TEC Data Fetched at -10.0\n",
      "Correlation Data saved at -10.0\n",
      "______________-7.5_______________\n",
      "TEC Data Fetched at -7.5\n",
      "Correlation Data saved at -7.5\n",
      "______________-5.0_______________\n",
      "TEC Data Fetched at -5.0\n",
      "Correlation Data saved at -5.0\n",
      "______________-2.5_______________\n",
      "TEC Data Fetched at -2.5\n",
      "Correlation Data saved at -2.5\n",
      "______________0.0_______________\n",
      "TEC Data Fetched at 0.0\n",
      "Correlation Data saved at 0.0\n",
      "______________2.5_______________\n",
      "TEC Data Fetched at 2.5\n",
      "Correlation Data saved at 2.5\n",
      "______________5.0_______________\n",
      "TEC Data Fetched at 5.0\n",
      "Correlation Data saved at 5.0\n",
      "______________7.5_______________\n",
      "TEC Data Fetched at 7.5\n",
      "Correlation Data saved at 7.5\n",
      "______________10.0_______________\n",
      "TEC Data Fetched at 10.0\n",
      "Correlation Data saved at 10.0\n",
      "______________12.5_______________\n",
      "TEC Data Fetched at 12.5\n",
      "Correlation Data saved at 12.5\n",
      "______________15.0_______________\n",
      "TEC Data Fetched at 15.0\n",
      "Correlation Data saved at 15.0\n",
      "______________17.5_______________\n",
      "TEC Data Fetched at 17.5\n",
      "Correlation Data saved at 17.5\n",
      "______________20.0_______________\n",
      "TEC Data Fetched at 20.0\n",
      "Correlation Data saved at 20.0\n",
      "______________22.5_______________\n",
      "TEC Data Fetched at 22.5\n",
      "Correlation Data saved at 22.5\n",
      "______________25.0_______________\n",
      "TEC Data Fetched at 25.0\n",
      "Correlation Data saved at 25.0\n",
      "______________27.5_______________\n",
      "TEC Data Fetched at 27.5\n",
      "Correlation Data saved at 27.5\n",
      "______________30.0_______________\n",
      "TEC Data Fetched at 30.0\n",
      "Correlation Data saved at 30.0\n",
      "______________32.5_______________\n",
      "TEC Data Fetched at 32.5\n",
      "Correlation Data saved at 32.5\n",
      "______________35.0_______________\n",
      "TEC Data Fetched at 35.0\n",
      "Correlation Data saved at 35.0\n",
      "______________37.5_______________\n",
      "TEC Data Fetched at 37.5\n",
      "Correlation Data saved at 37.5\n",
      "______________40.0_______________\n",
      "TEC Data Fetched at 40.0\n",
      "Correlation Data saved at 40.0\n",
      "______________42.5_______________\n",
      "TEC Data Fetched at 42.5\n",
      "Correlation Data saved at 42.5\n",
      "______________45.0_______________\n",
      "TEC Data Fetched at 45.0\n",
      "Correlation Data saved at 45.0\n",
      "______________47.5_______________\n",
      "TEC Data Fetched at 47.5\n",
      "Correlation Data saved at 47.5\n",
      "______________50.0_______________\n",
      "TEC Data Fetched at 50.0\n",
      "Correlation Data saved at 50.0\n",
      "______________52.5_______________\n",
      "TEC Data Fetched at 52.5\n",
      "Correlation Data saved at 52.5\n",
      "______________55.0_______________\n",
      "TEC Data Fetched at 55.0\n",
      "Correlation Data saved at 55.0\n",
      "______________57.5_______________\n",
      "TEC Data Fetched at 57.5\n",
      "Correlation Data saved at 57.5\n",
      "______________60.0_______________\n",
      "TEC Data Fetched at 60.0\n",
      "Correlation Data saved at 60.0\n",
      "______________62.5_______________\n",
      "TEC Data Fetched at 62.5\n",
      "Correlation Data saved at 62.5\n",
      "______________65.0_______________\n",
      "TEC Data Fetched at 65.0\n",
      "Correlation Data saved at 65.0\n",
      "______________67.5_______________\n",
      "TEC Data Fetched at 67.5\n",
      "Correlation Data saved at 67.5\n",
      "______________70.0_______________\n",
      "TEC Data Fetched at 70.0\n",
      "Correlation Data saved at 70.0\n",
      "______________72.5_______________\n",
      "TEC Data Fetched at 72.5\n",
      "Correlation Data saved at 72.5\n",
      "______________75.0_______________\n",
      "TEC Data Fetched at 75.0\n",
      "Correlation Data saved at 75.0\n",
      "______________77.5_______________\n",
      "TEC Data Fetched at 77.5\n",
      "Correlation Data saved at 77.5\n",
      "______________80.0_______________\n",
      "TEC Data Fetched at 80.0\n",
      "Correlation Data saved at 80.0\n",
      "______________82.5_______________\n",
      "TEC Data Fetched at 82.5\n",
      "Correlation Data saved at 82.5\n",
      "______________85.0_______________\n",
      "TEC Data Fetched at 85.0\n",
      "Correlation Data saved at 85.0\n",
      "______________87.5_______________\n",
      "TEC Data Fetched at 87.5\n",
      "Correlation Data saved at 87.5\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "testLatitudes = np.arange(-87.5, 90, 2.5)\n",
    "for latitude in testLatitudes:\n",
    "    print('______________' + str(latitude) + '_______________')\n",
    "    tec_data_file_values = getTECDataAtLatitude(latitude)\n",
    "    print('TEC Data Fetched at ' + str(latitude))\n",
    "    correlation_window_file_temp = calculateCorrelationWithWindow(latitude, tec_data_file_values, f10_7Data, swsData)\n",
    "    print('Correlation Data saved at ' + str(latitude))\n",
    "    \n",
    "#     finalDataFrame = correlation_window\n",
    "#     currentColumns = finalDataFrame.columns\n",
    "#     latitudeColumn = [latitude]\n",
    "#     finalDataFrame.columns = pd.MultiIndex.from_product([latitudeColumn, currentColumns], names=['latitude', 'data'])\n",
    "    \n",
    "print('end')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5300db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
